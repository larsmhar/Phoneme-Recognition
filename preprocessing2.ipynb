{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This file makes folders and processes the TIMIT dataset to filterbanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lars/Projects/tensorflowgputest/venv/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import scipy.io.wavfile\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to change output folder\n",
    "OUTPUT_PATH = Path('./MFCCS_DELTA_DELTA_NPY_LONGER')\n",
    "\n",
    "TRAIN_PATH = Path('./TRAIN_WAV')\n",
    "TEST_PATH = Path('./TEST_WAV')\n",
    "\n",
    "# All of the sub directories, such as TRAIN_PATH/DR1\n",
    "TRAIN_PATHS = [x for x in TRAIN_PATH.iterdir()]\n",
    "TEST_PATHS = [x for x in TEST_PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would have been possible to use grub or something similar here.\n",
    "But I figured that out quite late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the different accents/people talking\n",
    "TRAIN_ACCENTS = [[x for x in xs.iterdir()] for xs in TRAIN_PATHS]\n",
    "TEST_ACCENTS = [[x for x in xs.iterdir()] for xs in TEST_PATHS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('TRAIN_WAV/DR7/MMDG0/SX160'), PosixPath('TRAIN_WAV/DR7/MMDG0/SA1'), PosixPath('TRAIN_WAV/DR7/MMDG0/SA2'), PosixPath('TRAIN_WAV/DR7/MMDG0/SI2035'), PosixPath('TRAIN_WAV/DR7/MMDG0/SX340')]\n",
      "[PosixPath('TRAIN_WAV/DR7/MMDG0/SX160.PHN'), PosixPath('TRAIN_WAV/DR7/MMDG0/SA1.TXT'), PosixPath('TRAIN_WAV/DR7/MMDG0/SA1.WAV.wav'), PosixPath('TRAIN_WAV/DR7/MMDG0/SA2.PHN'), PosixPath('TRAIN_WAV/DR7/MMDG0/SX70.WAV.wav')]\n",
      "1718\n"
     ]
    }
   ],
   "source": [
    "pat = r'^([A-Z0-9]+)\\.[A-Z]+$'\n",
    "\n",
    "def get_files(pathss):\n",
    "    \"\"\"\n",
    "        Returns all of the files in a folder and\n",
    "        all of the file-groupings in a path.\n",
    "        For example if we have a folder with multiple files\n",
    "        such as path/test.png, path/test.txt etc.\n",
    "        Then this will return path/test\n",
    "    \"\"\"\n",
    "    FILES = []\n",
    "    for paths in pathss:\n",
    "        for xs in paths:\n",
    "            for x in xs.iterdir():\n",
    "                FILES.append(x)\n",
    "        #TRAIN_FILES.append([[x for x in xs.iterdir()] for xs in paths])\n",
    "    FILES_2 = []\n",
    "    matches = []\n",
    "\n",
    "    for x in FILES:\n",
    "        # I might be able to use x.stem insead of this\n",
    "        # Path has .match for regex matching also. Might be quicker and better\n",
    "        match = re.search(pat, x.name)\n",
    "        if match == None or match.group(1) in matches:\n",
    "            continue\n",
    "        FILES_2.append(x.with_suffix(''))\n",
    "        matches.append(match.group(1))\n",
    "    return FILES, FILES_2 \n",
    "\n",
    "# TRAIN_FILES here is the files while TRAIN_FILES_2 are the file groupings\n",
    "(TRAIN_FILES_ALL, TRAIN_FILES_GROUPINGS) = get_files(TRAIN_ACCENTS)\n",
    "(TEST_FILES_ALL, TEST_FILES_GROUPINGS) = get_files(TEST_ACCENTS)\n",
    "print(TRAIN_FILES_GROUPINGS[:5])\n",
    "print(TRAIN_FILES_ALL[:5])\n",
    "#print(TEST_FILES_2[:5])\n",
    "print(len(TRAIN_FILES_GROUPINGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(OUTPUT_PATH)\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_phones = [\"h#\"]\n",
    "#from Lee & Hon, 1989\n",
    "phone_transfers = {\n",
    "    \"ao\": \"aa\",\n",
    "    \"ax\": \"ah\",\n",
    "    \"ax-h\": \"ah\",\n",
    "    \"axr\": \"er\",\n",
    "    \"hv\": \"hh\",\n",
    "    \"ix\": \"ih\",\n",
    "    \"el\": \"l\",\n",
    "    \"em\": \"m\",\n",
    "    \"en\": \"n\",\n",
    "    \"nx\": \"n\",\n",
    "    \"eng\": \"ng\",\n",
    "    \"zh\": \"sh\",\n",
    "    \"ux\": \"uw\",\n",
    "    \"pcl\": \"sil\",\n",
    "    \"tcl\": \"sil\",\n",
    "    \"kcl\": \"sil\",\n",
    "    \"bcl\": \"sil\",\n",
    "    \"dcl\": \"sil\",\n",
    "    \"gcl\": \"sil\",\n",
    "    \"h#\": \"sil\",\n",
    "    \"pau\": \"sil\",\n",
    "    \"epi\": \"sil\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_phn(file, i):\n",
    "    \"\"\"\n",
    "        Gets the phone of file file at time i\n",
    "    \"\"\"\n",
    "    phns = pd.read_csv(Path(file).with_suffix(\"\").with_suffix('.PHN'), sep = \" \" , header=None)\n",
    "    phn = phns[2][0]\n",
    "    length = int(phns[1][0]) - int(phns[0][0])\n",
    "    for idx, x in enumerate(phns[0]):\n",
    "        #print(i, idx, x, phns[2][idx])\n",
    "        if i >= x:\n",
    "            phn = phns[2][idx]\n",
    "            length = int(phns[1][idx]) - int(phns[0][idx])\n",
    "            continue\n",
    "        return phn, length\n",
    "        break\n",
    "    else:\n",
    "        return phn, int(phns[1][idx - 1]) - int(phns[0][idx - 1])\n",
    "            \n",
    "def normalize(arr):\n",
    "    # from : https://stackoverflow.com/questions/31152967/normalise-2d-numpy-array-zero-mean-unit-variance\n",
    "    return (arr - arr.mean(axis=0)) / arr.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavfile_to_mfccs(path, labels_file, idx=\"TRAIN_WAV\"):\n",
    "    #(sampling_rate, _sig) = scipy.io.wavfile.read(path)\n",
    "    file = path\n",
    "    (_sig, sampling_rate) = librosa.load(path, sr = 16000)\n",
    "    window = int(400 * 2.8 / 2)\n",
    "    for i in range(0, len(_sig) - 150, window):\n",
    "        for mult in range(2):\n",
    "            i = int(i + mult * (window / 2))\n",
    "            if len(_sig) - i < window + 1:\n",
    "                break\n",
    "                \n",
    "            sig = _sig[i: i + window]  \n",
    "            \n",
    "            segment_duration_ms = 25\n",
    "            n_fft = int((segment_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "            # To get 15 x 3 samples\n",
    "            hop_duration_ms = 5/2\n",
    "            hop_length = int((hop_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "            mfcc_count = 40\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(\n",
    "                y=sig,\n",
    "                sr=sampling_rate,\n",
    "                n_mfcc=mfcc_count,\n",
    "                hop_length=hop_length,\n",
    "                n_fft=n_fft\n",
    "            )\n",
    "            mfcc_delta = librosa.feature.delta(mfccs, width = 3)\n",
    "            mfcc_delta2 = librosa.feature.delta(mfccs, order=2, width = 3)\n",
    "            mfccs_and_deltas = np.hstack([mfccs, mfcc_delta, mfcc_delta2])\n",
    "            \n",
    "            mfccs_and_deltas = normalize(mfccs_and_deltas)\n",
    "            \n",
    "            label, phn_length = get_phn(path, i)\n",
    "            \n",
    "            if label in phone_transfers.keys():\n",
    "                    label = phone_transfers[label]\n",
    "                    \n",
    "            if (label == \"q\"): \n",
    "                continue\n",
    "            yield mfccs_and_deltas, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_timit_line(self, line):\n",
    "    start_frame, end_frame, label = line.split(' ')\n",
    "\n",
    "    return int(start_frame), int(end_frame), label.strip('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavfile_to_mfccs(path, labels_file, idx=\"TRAIN_WAV\"):\n",
    "    #(sampling_rate, _sig) = scipy.io.wavfile.read(path)\n",
    "    file = path\n",
    "    (_sig, sampling_rate) = librosa.load(path, sr = 16000)\n",
    "    window = int(400 * 2.8 / 2)\n",
    "    for i in range(0, len(_sig) - 150, window):\n",
    "        for mult in range(2):\n",
    "            i = int(i + mult * (window / 2))\n",
    "            if len(_sig) - i < window + 1:\n",
    "                break\n",
    "                \n",
    "            sig = _sig[i: i + window]  \n",
    "            \n",
    "            segment_duration_ms = 25\n",
    "            n_fft = int((segment_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "            # To get 15 x 3 samples\n",
    "            hop_duration_ms = 5/2\n",
    "            hop_length = int((hop_duration_ms / 1000.) * sampling_rate)\n",
    "\n",
    "            mfcc_count = 40\n",
    "\n",
    "            mfccs = librosa.feature.mfcc(\n",
    "                y=sig,\n",
    "                sr=sampling_rate,\n",
    "                n_mfcc=mfcc_count,\n",
    "                hop_length=hop_length,\n",
    "                n_fft=n_fft\n",
    "            )\n",
    "            mfcc_delta = librosa.feature.delta(mfccs, width = 3)\n",
    "            mfcc_delta2 = librosa.feature.delta(mfccs, order=2, width = 3)\n",
    "            mfccs_and_deltas = np.hstack([mfccs, mfcc_delta, mfcc_delta2])\n",
    "            \n",
    "            mfccs_and_deltas = normalize(mfccs_and_deltas)\n",
    "            \n",
    "            labels = []\n",
    "\n",
    "            with open(labels_file, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    start_frame, end_frame, label = self._parse_timit_line(line)\n",
    "\n",
    "                    phn_frames = end_frame - start_frame\n",
    "                    labels.extend([label] * phn_frames)\n",
    "\n",
    "            label, phn_length = get_phn(path, i)\n",
    "            \n",
    "            labels.extend([label] * phn_length)\n",
    "                    \n",
    "            if (len(labels[i: i+window]) > 0) :\n",
    "                label = max(labels[i: i + window])\n",
    "            if label in phone_transfers.keys():\n",
    "                    label = phone_transfers[label]\n",
    "            if (label == \"q\"): \n",
    "                continue\n",
    "        \n",
    "            yield mfccs_and_deltas, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wavfiles_to_mfccs(files):\n",
    "    print(len(files))\n",
    "    \n",
    "    X, y = [], []\n",
    "    divider = len(files)\n",
    "    print(\"Starting converting...\")\n",
    "    for i, file in enumerate(files):\n",
    "        if (i % int(divider/20) == 0): print(f\"{i / divider :.2f}\")\n",
    "        for mfccs, label in wavfile_to_mfccs(file.with_suffix(\".WAV.wav\"), file.with_suffix(\".PHN\")):\n",
    "            if (label != \"q\"):\n",
    "                X.append(normalize(mfccs))\n",
    "                y.append(label)\n",
    "    print(\"Done\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1718\n",
      "Starting converting...\n",
      "0.00\n",
      "0.05\n",
      "0.10\n",
      "0.15\n",
      "0.20\n",
      "0.25\n",
      "0.30\n",
      "0.35\n",
      "0.40\n",
      "0.45\n",
      "0.49\n",
      "0.54\n",
      "0.59\n",
      "0.64\n",
      "0.69\n",
      "0.74\n",
      "0.79\n",
      "0.84\n",
      "0.89\n",
      "0.94\n",
      "0.99\n",
      "Done\n",
      "626\n",
      "Starting converting...\n",
      "0.00\n",
      "0.05\n",
      "0.10\n",
      "0.15\n",
      "0.20\n",
      "0.25\n",
      "0.30\n",
      "0.35\n",
      "0.40\n",
      "0.45\n",
      "0.50\n",
      "0.54\n",
      "0.59\n",
      "0.64\n",
      "0.69\n",
      "0.74\n",
      "0.79\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "X, y = read_wavfiles_to_mfccs(TRAIN_FILES_GROUPINGS)\n",
    "\n",
    "OUTPUT_PATH = \"TEST_HIS_METHOD\"\n",
    "\n",
    "np.save(OUTPUT_PATH / \"X_train\", X)\n",
    "np.save(OUTPUT_PATH / \"y_train\", y)\n",
    "\n",
    "X, y= read_wavfiles_to_mfccs(TEST_FILES_GROUPINGS)\n",
    "\n",
    "np.save(OUTPUT_PATH / \"X_test\", X)\n",
    "np.save(OUTPUT_PATH / \"y_test\", y)\n",
    "\n",
    "X,y = \"\", \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626\n"
     ]
    }
   ],
   "source": [
    "print(len(TEST_FILES_GROUPINGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
