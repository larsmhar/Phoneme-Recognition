{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is from https://fehiepsi.github.io/blog/grapheme-to-phoneme/\n",
    "# Based on https://github.com/SeanNaren/deepspeech.pytorch/blob/master/decoder.py.\n",
    "import Levenshtein  # https://github.com/ztane/python-Levenshtein/\n",
    "\n",
    "\n",
    "def phoneme_error_rate(p_seq1, p_seq2):\n",
    "    # To calculate the PER\n",
    "    p_vocab = set(p_seq1 + p_seq2)\n",
    "    p2c = dict(zip(p_vocab, range(len(p_vocab))))\n",
    "    c_seq1 = [chr(p2c[p]) for p in p_seq1]\n",
    "    c_seq2 = [chr(p2c[p]) for p in p_seq2]\n",
    "    return Levenshtein.distance(''.join(c_seq1),\n",
    "                                ''.join(c_seq2)) / len(c_seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are so that we can map the phonemes to integers and then back to phonemes\n",
    "phones = [\n",
    "    \"aa\",\n",
    "    \"ae\",\n",
    "    \"ah\",\n",
    "    \"ay\",\n",
    "    \"aw\",\n",
    "    \"b\",\n",
    "    \"ch\",\n",
    "    \"d\",\n",
    "    \"dh\",\n",
    "    \"dx\",\n",
    "    \"eh\",\n",
    "    \"er\",\n",
    "    \"ey\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"hh\",\n",
    "    \"ih\",\n",
    "    \"k\",\n",
    "    \"iy\",\n",
    "    \"jh\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"ng\",\n",
    "    \"oy\",\n",
    "    \"ow\",\n",
    "    \"r\",\n",
    "    \"s\",\n",
    "    \"sh\",\n",
    "    \"t\",\n",
    "    \"th\",\n",
    "    \"uw\",\n",
    "    \"uh\",\n",
    "    \"p\",\n",
    "    \"v\",\n",
    "    \"w\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"sil\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"DATASET\")\n",
    "\n",
    "trainX = np.load(path / \"X_train.npy\")\n",
    "trainY = np.load(path / \"y_train.npy\")\n",
    "\n",
    "testX = np.load(path / \"X_test.npy\")\n",
    "testY = np.load(path / \"y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "char_to_int = dict((c, i) for i, c in enumerate(phones))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(phones))\n",
    "trainY = [char_to_int[phone] for phone in trainY]\n",
    "testY = [char_to_int[phone] for phone in testY]\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "trainY = to_categorical(trainY)\n",
    "testY= to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.reshape((-1, trainX.shape[1], trainX.shape[2], 1))\n",
    "testX = testX.reshape((-1, testX.shape[1], testX.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(\n",
    "        trainX, trainY, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "output_dim = len(trainY[0])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(150,\n",
    "                        (8, 8), \n",
    "                        input_shape=(trainX.shape[1], trainX.shape[2], 1),\n",
    "                        activation = 'relu'))\n",
    "model.add(MaxPooling2D((6,6),\n",
    "                      padding=\"same\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "    \n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(output_dim=output_dim, activation = 'softmax'))\n",
    "model.summary() \n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "      metrics=[\"accuracy\"],\n",
    "      optimizer=Adam(lr=0.001)\n",
    ")\n",
    "\n",
    "stats = model.fit(trainX, trainY,\n",
    "        shuffle=True,\n",
    "        batch_size=1024,\n",
    "        epochs=11,\n",
    "        validation_split=0.1,\n",
    "        verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(x=testX, batch_size=512, verbose=1)\n",
    "print(f\"PER is : {phoneme_error_rate(predictions.argmax(axis=1), testY.argmax(axis=1))} Accuracy is : {model.evaluate(x=testX, y = testY, batch_size=512, verbose=1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dim = len(trainY[0])\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation = 'relu'))\n",
    "model2.add(Dense(256, activation = 'relu'))\n",
    "model2.add(Dense(output_dim=output_dim, activation = 'relu'))\n",
    "model2.add(Dense(output_dim=output_dim))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "stats = model2.fit(trainX, trainY,\n",
    "    shuffle=True,\n",
    "    batch_size=2048,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=testX, batch_size=512, verbose=1)\n",
    "print(f\"PER is : {phoneme_error_rate(predictions.argmax(axis=1), testY.argmax(axis=1))} Accuracy is : {model.evaluate(x=testX, y = testY, batch_size=512, verbose=1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mainly used to get the confusion matrix\n",
    "# This code is copied from somewhere, but I can sadly not figure out where that was from.\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(testX[0].shape)\n",
    "print(trainX[0].shape)\n",
    "predictions = model.predict(x=testX, batch_size=512, verbose=1)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1)))\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, epochs)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, stats.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, stats.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model2.predict(x=testX, batch_size=512, verbose=1)\n",
    "print(f\"PER is : {phoneme_error_rate(predictions.argmax(axis=1), testY.argmax(axis=1))} Accuracy is : {model2.evaluate(x=testX, y = testY, batch_size=512, verbose=1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PER of tests\n",
    "#### CNN Test Result 8.24\n",
    "0.6514674425125122\n",
    "\n",
    "0.6436238884925842\n",
    "\n",
    "0.6488529443740845\n",
    "\n",
    "#### CNN Horizontal Test Result (40x1) 2.3M\n",
    "0.6527880430221558\n",
    "\n",
    "0.6515655517578125\n",
    "\n",
    "0.6558755040168762\n",
    "\n",
    "#### Small CNN Horizontal Test Result (40x1) 181k  pars\n",
    "0.641758918762207\n",
    "\n",
    "0.6443377733230591\n",
    "\n",
    "0.6448642611503601\n",
    "\n",
    "#### Small CNN 181k params (40x8)\n",
    "0.6403490900993347\n",
    "\n",
    "0.6396352052688599\n",
    "\n",
    "0.6392336487770081\n",
    "\n",
    "#### DNN Test Result 6,8M\n",
    "0.6274282336235046\n",
    "\n",
    "0.6198791861534119\n",
    "\n",
    "0.6232432126998901\n",
    "\n",
    "#### DNN 256 * 2 567k\n",
    "0.5806347727775574\n",
    "\n",
    "0.5770119428634644\n",
    "\n",
    "0.575503945350647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn = [0.6514674425125122,0.6436238884925842,0.6488529443740845]\n",
    "\n",
    "cnn2 = [0.6527880430221558, 0.6515655517578125, 0.6558755040168762]\n",
    "\n",
    "cnn3 = [0.6403490900993347, 0.6396352052688599, 0.6392336487770081]\n",
    "\n",
    "cnn4 = [0.641758918762207, 0.6443377733230591, 0.6448642611503601]\n",
    "\n",
    "dnn = [0.6274282336235046, 0.6198791861534119, 0.6232432126998901]\n",
    "\n",
    "dnn2 = [0.5806347727775574, 0.5770119428634644, 0.575503945350647]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
